{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shihch3\\Anaconda3\\envs\\msmonai_05_v2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.1.0\n",
      "Numpy version: 1.23.5\n",
      "Pytorch version: 2.0.0+cpu\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: a2ec3752f54bfc3b40e7952234fbeb5452ed63e3\n",
      "MONAI __file__: c:\\Users\\shihch3\\Anaconda3\\envs\\msmonai_05_v2\\lib\\site-packages\\monai\\__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.11\n",
      "Nibabel version: 5.0.1\n",
      "scikit-image version: 0.20.0\n",
      "Pillow version: 9.4.0\n",
      "Tensorboard version: 2.12.0\n",
      "gdown version: 4.7.1\n",
      "TorchVision version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "tqdm version: 4.65.0\n",
      "lmdb version: 1.4.0\n",
      "psutil version: 5.9.0\n",
      "pandas version: 1.5.3\n",
      "einops version: 0.6.0\n",
      "transformers version: 4.27.3\n",
      "mlflow version: 2.2.2\n",
      "pynrrd version: 1.0.0\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from monai.utils import progress_bar, set_determinism\n",
    "from monai.transforms import (\n",
    "    EnsureChannelFirst,\n",
    "    AddChannel,\n",
    "    Compose,\n",
    "    RandFlip,\n",
    "    RandRotate,\n",
    "    RandZoom,\n",
    "    ScaleIntensity,\n",
    "    EnsureType,\n",
    "    Transform,\n",
    ")\n",
    "from monai.networks.nets import Discriminator, Generator\n",
    "from monai.networks import normal_init\n",
    "from monai.data import CacheDataset\n",
    "from monai.config import print_config\n",
    "from monai.apps import download_and_extract\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_determinism(seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_train_interval = 1\n",
    "disc_train_steps = 5\n",
    "batch_size = 300\n",
    "latent_size = 64\n",
    "max_epochs = 50\n",
    "real_label = 1\n",
    "gen_label = 0\n",
    "learning_rate = 2e-4\n",
    "betas = (0.5, 0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "# root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "# print(root_dir)\n",
    "root_dir = \"Y:\\shihch3\\data\\\\tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MedNIST.tar.gz: 59.0MB [00:05, 11.8MB/s]                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-25 17:14:12,456 - INFO - Downloaded: Y:\\shihch3\\data\\tmp\\MedNIST.tar.gz\n",
      "2023-03-25 17:14:13,359 - INFO - Verified 'MedNIST.tar.gz', md5: 0bc7306e7427e00ad1c5526a6677552d.\n",
      "2023-03-25 17:14:13,361 - INFO - Writing into directory: Y:\\shihch3\\data\\tmp.\n"
     ]
    }
   ],
   "source": [
    "resource = \"https://github.com/Project-MONAI/MONAI-extra-test-data/releases/download/0.8.1/MedNIST.tar.gz\"\n",
    "md5 = \"0bc7306e7427e00ad1c5526a6677552d\"\n",
    "\n",
    "compressed_file = os.path.join(root_dir, \"MedNIST.tar.gz\")\n",
    "data_dir = os.path.join(root_dir, \"MedNIST\")\n",
    "if not os.path.exists(data_dir):\n",
    "    download_and_extract(resource, compressed_file, root_dir, md5)\n",
    "\n",
    "hands = [os.path.join(data_dir, \"Hand\", x) for x in os.listdir(os.path.join(data_dir, \"Hand\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shihch3\\Anaconda3\\envs\\msmonai_05_v2\\lib\\site-packages\\monai\\utils\\deprecate_utils.py:107: FutureWarning: <class 'monai.transforms.utility.array.AddChannel'>: Class `AddChannel` has been deprecated since version 0.8. please use MetaTensor data type and monai.transforms.EnsureChannelFirst instead.\n",
      "  warn_deprecated(obj, msg, warning_category)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 19\u001b[0m\n\u001b[0;32m      6\u001b[0m train_transforms \u001b[39m=\u001b[39m Compose(\n\u001b[0;32m      7\u001b[0m     [\n\u001b[0;32m      8\u001b[0m         LoadTarJpeg(),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m     ]\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     18\u001b[0m train_ds \u001b[39m=\u001b[39m CacheDataset(hands, train_transforms)\n\u001b[1;32m---> 19\u001b[0m train_loader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mDataLoader(train_ds, batch_size\u001b[39m=\u001b[39;49mbatch_size, shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, num_workers\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\shihch3\\Anaconda3\\envs\\msmonai_05_v2\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:351\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# map-style\u001b[39;00m\n\u001b[0;32m    350\u001b[0m     \u001b[39mif\u001b[39;00m shuffle:\n\u001b[1;32m--> 351\u001b[0m         sampler \u001b[39m=\u001b[39m RandomSampler(dataset, generator\u001b[39m=\u001b[39;49mgenerator)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    352\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    353\u001b[0m         sampler \u001b[39m=\u001b[39m SequentialSampler(dataset)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\shihch3\\Anaconda3\\envs\\msmonai_05_v2\\lib\\site-packages\\torch\\utils\\data\\sampler.py:107\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[1;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mreplacement should be a boolean value, but got \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    104\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mreplacement=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplacement))\n\u001b[0;32m    106\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples, \u001b[39mint\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 107\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mnum_samples should be a positive integer \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    108\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mvalue, but got num_samples=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples))\n",
      "\u001b[1;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "class LoadTarJpeg(Transform):\n",
    "    def __call__(self, data):\n",
    "        return plt.imread(data)\n",
    "\n",
    "\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadTarJpeg(),\n",
    "        AddChannel(),\n",
    "        ScaleIntensity(),\n",
    "        RandRotate(range_x=np.pi / 12, prob=0.5, keep_size=True),\n",
    "        RandFlip(spatial_axis=0, prob=0.5),\n",
    "        RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5),\n",
    "        EnsureType(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_ds = CacheDataset(hands, train_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.backends.mps.is_available())\n",
    "print(torch.backends.mps.is_built())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "disc_net = Discriminator(\n",
    "    in_shape=(1, 64, 64),\n",
    "    channels=(8, 16, 32, 64, 1),\n",
    "    strides=(2, 2, 2, 2, 1),\n",
    "    num_res_units=1,\n",
    "    kernel_size=5,\n",
    ").to(device)\n",
    "\n",
    "gen_net = Generator(\n",
    "    latent_shape=latent_size,\n",
    "    start_shape=(64, 8, 8),\n",
    "    channels=[32, 16, 8, 1],\n",
    "    strides=[2, 2, 2, 1],\n",
    ")\n",
    "\n",
    "# initialize both networks\n",
    "disc_net.apply(normal_init)\n",
    "gen_net.apply(normal_init)\n",
    "\n",
    "# input images are scaled to [0,1] so enforce the same of generated outputs\n",
    "gen_net.conv.add_module(\"activation\", torch.nn.Sigmoid())\n",
    "gen_net = gen_net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_loss = torch.nn.BCELoss()\n",
    "gen_loss = torch.nn.BCELoss()\n",
    "\n",
    "disc_opt = torch.optim.Adam(disc_net.parameters(), learning_rate, betas=betas)\n",
    "gen_opt = torch.optim.Adam(gen_net.parameters(), learning_rate, betas=betas)\n",
    "\n",
    "\n",
    "def discriminator_loss(gen_images, real_images):\n",
    "    \"\"\"\n",
    "    The discriminator loss if calculated by comparing its\n",
    "    prediction for real and generated images.\n",
    "\n",
    "    \"\"\"\n",
    "    real = real_images.new_full((real_images.shape[0], 1), real_label)\n",
    "    gen = gen_images.new_full((gen_images.shape[0], 1), gen_label)\n",
    "\n",
    "    realloss = disc_loss(disc_net(real_images), real)\n",
    "    genloss = disc_loss(disc_net(gen_images.detach()), gen)\n",
    "\n",
    "    return (realloss + genloss) / 2\n",
    "\n",
    "\n",
    "def generator_loss(input):\n",
    "    \"\"\"\n",
    "    The generator loss is calculated by determining how well\n",
    "    the discriminator was fooled by the generated images.\n",
    "\n",
    "    \"\"\"\n",
    "    output = disc_net(input)\n",
    "    cats = output.new_full(output.shape, real_label)\n",
    "    return gen_loss(output, cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikeshih/opt/anaconda3/envs/monai/lib/python3.9/site-packages/torch/_tensor.py:1295: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  ret = func(*args, **kwargs)\n",
      "/Users/mikeshih/opt/anaconda3/envs/monai/lib/python3.9/site-packages/monai/data/__init__.py:127: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  if storage.is_cuda:\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/mikeshih/opt/anaconda3/envs/monai/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/mikeshih/opt/anaconda3/envs/monai/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'LoadTarJpeg' on <module '__main__' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "epoch_loss_values = [(0, 0)]\n",
    "gen_step_loss = []\n",
    "disc_step_loss = []\n",
    "step = 0\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    gen_net.train()\n",
    "    disc_net.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for i, batch_data in enumerate(train_loader):\n",
    "        progress_bar(\n",
    "            i,\n",
    "            len(train_loader),\n",
    "            f\"epoch {epoch + 1}, avg loss: {epoch_loss_values[-1][1]:.4f}\",\n",
    "        )\n",
    "        real_images = batch_data.to(device)\n",
    "        latent = torch.randn(real_images.shape[0], latent_size).to(device)\n",
    "\n",
    "        gen_opt.zero_grad()\n",
    "        gen_images = gen_net(latent)\n",
    "        loss = generator_loss(gen_images)\n",
    "        loss.backward()\n",
    "        gen_opt.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        gen_step_loss.append((step, loss.item()))\n",
    "\n",
    "        if step % disc_train_interval == 0:\n",
    "            disc_total_loss = 0\n",
    "\n",
    "            for _ in range(disc_train_steps):\n",
    "                disc_opt.zero_grad()\n",
    "                dloss = discriminator_loss(gen_images, real_images)\n",
    "                dloss.backward()\n",
    "                disc_opt.step()\n",
    "                disc_total_loss += dloss.item()\n",
    "\n",
    "            disc_step_loss.append((step, disc_total_loss / disc_train_steps))\n",
    "\n",
    "        step += 1\n",
    "\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append((step, epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
