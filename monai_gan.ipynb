{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.1.0\n",
      "Numpy version: 1.23.5\n",
      "Pytorch version: 2.0.0\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: a2ec3752f54bfc3b40e7952234fbeb5452ed63e3\n",
      "MONAI __file__: /Users/mikeshih/opt/anaconda3/envs/monai/lib/python3.9/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.11\n",
      "Nibabel version: 5.0.1\n",
      "scikit-image version: 0.20.0\n",
      "Pillow version: 9.4.0\n",
      "Tensorboard version: 2.12.0\n",
      "gdown version: 4.7.1\n",
      "TorchVision version: 0.15.1\n",
      "tqdm version: 4.65.0\n",
      "lmdb version: 1.4.0\n",
      "psutil version: 5.9.4\n",
      "pandas version: 1.5.3\n",
      "einops version: 0.6.0\n",
      "transformers version: 4.27.3\n",
      "mlflow version: 2.2.2\n",
      "pynrrd version: 1.0.0\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from monai.utils import progress_bar, set_determinism\n",
    "from monai.transforms import (\n",
    "    EnsureChannelFirst,\n",
    "    AddChannel,\n",
    "    Compose,\n",
    "    RandFlip,\n",
    "    RandRotate,\n",
    "    RandZoom,\n",
    "    ScaleIntensity,\n",
    "    EnsureType,\n",
    "    Transform,\n",
    ")\n",
    "from monai.networks.nets import Discriminator, Generator\n",
    "from monai.networks import normal_init\n",
    "from monai.data import CacheDataset\n",
    "from monai.config import print_config\n",
    "from monai.apps import download_and_extract\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_determinism(seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_train_interval = 1\n",
    "disc_train_steps = 5\n",
    "batch_size = 300\n",
    "latent_size = 64\n",
    "max_epochs = 50\n",
    "real_label = 1\n",
    "gen_label = 0\n",
    "learning_rate = 2e-4\n",
    "betas = (0.5, 0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "# root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "# print(root_dir)\n",
    "root_dir = \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MedNIST.tar.gz: 59.0MB [00:07, 8.83MB/s]                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-25 15:54:59,849 - INFO - Downloaded: MedNIST.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-25 15:54:59,986 - INFO - Verified 'MedNIST.tar.gz', md5: 0bc7306e7427e00ad1c5526a6677552d.\n",
      "2023-03-25 15:54:59,987 - INFO - Writing into directory: ..\n"
     ]
    }
   ],
   "source": [
    "resource = \"https://github.com/Project-MONAI/MONAI-extra-test-data/releases/download/0.8.1/MedNIST.tar.gz\"\n",
    "md5 = \"0bc7306e7427e00ad1c5526a6677552d\"\n",
    "\n",
    "compressed_file = os.path.join(root_dir, \"MedNIST.tar.gz\")\n",
    "data_dir = os.path.join(root_dir, \"MedNIST\")\n",
    "if not os.path.exists(data_dir):\n",
    "    download_and_extract(resource, compressed_file, root_dir, md5)\n",
    "\n",
    "hands = [os.path.join(data_dir, \"Hand\", x) for x in os.listdir(os.path.join(data_dir, \"Hand\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 10000/10000 [00:03<00:00, 2688.05it/s]\n"
     ]
    }
   ],
   "source": [
    "class LoadTarJpeg(Transform):\n",
    "    def __call__(self, data):\n",
    "        return plt.imread(data)\n",
    "\n",
    "\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadTarJpeg(),\n",
    "        AddChannel(),\n",
    "        ScaleIntensity(),\n",
    "        RandRotate(range_x=np.pi / 12, prob=0.5, keep_size=True),\n",
    "        RandFlip(spatial_axis=0, prob=0.5),\n",
    "        RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5),\n",
    "        EnsureType(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_ds = CacheDataset(hands, train_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.backends.mps.is_available())\n",
    "print(torch.backends.mps.is_built())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")\n",
    "disc_net = Discriminator(\n",
    "    in_shape=(1, 64, 64),\n",
    "    channels=(8, 16, 32, 64, 1),\n",
    "    strides=(2, 2, 2, 2, 1),\n",
    "    num_res_units=1,\n",
    "    kernel_size=5,\n",
    ").to(device)\n",
    "\n",
    "gen_net = Generator(\n",
    "    latent_shape=latent_size,\n",
    "    start_shape=(64, 8, 8),\n",
    "    channels=[32, 16, 8, 1],\n",
    "    strides=[2, 2, 2, 1],\n",
    ")\n",
    "\n",
    "# initialize both networks\n",
    "disc_net.apply(normal_init)\n",
    "gen_net.apply(normal_init)\n",
    "\n",
    "# input images are scaled to [0,1] so enforce the same of generated outputs\n",
    "gen_net.conv.add_module(\"activation\", torch.nn.Sigmoid())\n",
    "gen_net = gen_net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_loss = torch.nn.BCELoss()\n",
    "gen_loss = torch.nn.BCELoss()\n",
    "\n",
    "disc_opt = torch.optim.Adam(disc_net.parameters(), learning_rate, betas=betas)\n",
    "gen_opt = torch.optim.Adam(gen_net.parameters(), learning_rate, betas=betas)\n",
    "\n",
    "\n",
    "def discriminator_loss(gen_images, real_images):\n",
    "    \"\"\"\n",
    "    The discriminator loss if calculated by comparing its\n",
    "    prediction for real and generated images.\n",
    "\n",
    "    \"\"\"\n",
    "    real = real_images.new_full((real_images.shape[0], 1), real_label)\n",
    "    gen = gen_images.new_full((gen_images.shape[0], 1), gen_label)\n",
    "\n",
    "    realloss = disc_loss(disc_net(real_images), real)\n",
    "    genloss = disc_loss(disc_net(gen_images.detach()), gen)\n",
    "\n",
    "    return (realloss + genloss) / 2\n",
    "\n",
    "\n",
    "def generator_loss(input):\n",
    "    \"\"\"\n",
    "    The generator loss is calculated by determining how well\n",
    "    the discriminator was fooled by the generated images.\n",
    "\n",
    "    \"\"\"\n",
    "    output = disc_net(input)\n",
    "    cats = output.new_full(output.shape, real_label)\n",
    "    return gen_loss(output, cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikeshih/opt/anaconda3/envs/monai/lib/python3.9/site-packages/torch/_tensor.py:1295: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  ret = func(*args, **kwargs)\n",
      "/Users/mikeshih/opt/anaconda3/envs/monai/lib/python3.9/site-packages/monai/data/__init__.py:127: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  if storage.is_cuda:\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/mikeshih/opt/anaconda3/envs/monai/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/mikeshih/opt/anaconda3/envs/monai/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'LoadTarJpeg' on <module '__main__' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "epoch_loss_values = [(0, 0)]\n",
    "gen_step_loss = []\n",
    "disc_step_loss = []\n",
    "step = 0\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    gen_net.train()\n",
    "    disc_net.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for i, batch_data in enumerate(train_loader):\n",
    "        progress_bar(\n",
    "            i,\n",
    "            len(train_loader),\n",
    "            f\"epoch {epoch + 1}, avg loss: {epoch_loss_values[-1][1]:.4f}\",\n",
    "        )\n",
    "        real_images = batch_data.to(device)\n",
    "        latent = torch.randn(real_images.shape[0], latent_size).to(device)\n",
    "\n",
    "        gen_opt.zero_grad()\n",
    "        gen_images = gen_net(latent)\n",
    "        loss = generator_loss(gen_images)\n",
    "        loss.backward()\n",
    "        gen_opt.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        gen_step_loss.append((step, loss.item()))\n",
    "\n",
    "        if step % disc_train_interval == 0:\n",
    "            disc_total_loss = 0\n",
    "\n",
    "            for _ in range(disc_train_steps):\n",
    "                disc_opt.zero_grad()\n",
    "                dloss = discriminator_loss(gen_images, real_images)\n",
    "                dloss.backward()\n",
    "                disc_opt.step()\n",
    "                disc_total_loss += dloss.item()\n",
    "\n",
    "            disc_step_loss.append((step, disc_total_loss / disc_train_steps))\n",
    "\n",
    "        step += 1\n",
    "\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append((step, epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monai",
   "language": "python",
   "name": "monai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
